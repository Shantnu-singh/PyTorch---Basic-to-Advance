{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create tensor\n",
    "torch.empty(2,4)\n",
    "\n",
    "torch.ones(2,3 , dtype= torch.float64)\n",
    "\n",
    "a = torch.tensor([[2,3,4 ] ,[2,3 ,4 ]] , dtype= torch.float64)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5189, 0.6605, 0.3758],\n",
       "        [0.5124, 0.6289, 0.9076]], dtype=torch.float64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create tensor of same size \n",
    "torch.empty_like(a)\n",
    "\n",
    "torch.zeros_like(a)\n",
    "\n",
    "torch.ones_like(a)\n",
    "\n",
    "torch.rand_like(a) # genreta values betwwen 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data type in tensor\n",
    "a.dtype\n",
    "\n",
    "b = torch.tensor([ -.5,2.3 , 4, 4] , dtype= torch.float64)\n",
    "\n",
    "# b.to(torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.0000, 2.3000, 3.0000, 3.0000], dtype=torch.float64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# maths on tensor - scaler \n",
    "b + 1\n",
    "\n",
    "b*3\n",
    "\n",
    "b/3\n",
    "\n",
    "(b*100)//2\n",
    "\n",
    "((b*100)//2)%3\n",
    "\n",
    "b.abs()\n",
    "torch.neg(b)\n",
    "torch.abs(b)\n",
    "b.ceil()\n",
    "b.floor()\n",
    "torch.clamp(b , 2,3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3628, 0.1295, 0.1326],\n",
       "        [0.0158, 0.4813, 0.1605]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# maths on tensor - between two tensor\n",
    "a = torch.rand(2,3)\n",
    "b = torch.rand(2,3)\n",
    "\n",
    "a+b\n",
    "a+b\n",
    "a*b\n",
    "a/b\n",
    "a//b\n",
    "a%b\n",
    "\n",
    "# torch.matmul(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3247)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reducing matrix\n",
    "a = torch.ones(3,2)\n",
    "\n",
    "torch.sum(a)\n",
    "torch.sum(a , dim = 0) # along column\n",
    "torch.mean(a , dim = 1) # along row\n",
    "torch.max(a)\n",
    "torch.prod(a,dim = 0)\n",
    "torch.std( a , dim = 1)\n",
    "torch.argmax(a)\n",
    "torch.argmin(a)\n",
    "torch.relu(a)\n",
    "torch.softmax(a , dim = 0)\n",
    "\n",
    "trans_a = torch.transpose(a , 1,0)\n",
    "trans_a\n",
    "\n",
    "temp = torch.rand(3,3)\n",
    "torch.det(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False],\n",
       "        [False, False, False]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comparision operation\n",
    "i = torch.tensor([[2,3,4], [3,4,5]] , dtype= torch.float64)\n",
    "j = torch.tensor([[4,5,6],[1,2,4]], dtype= torch.float64)\n",
    "\n",
    "i>j\n",
    "i<=j\n",
    "i!= j\n",
    "i == j\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 3., 4.],\n",
       "        [3., 4., 5.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inplace Operation\n",
    "j.add_(i)\n",
    "j.sub_(i)\n",
    "torch.relu_(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[4., 5., 6.],\n",
       "         [1., 2., 4.]], dtype=torch.float64),\n",
       " tensor([[4., 5., 6.],\n",
       "         [1., 2., 4.]], dtype=torch.float64))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy a tensor\n",
    "i = j\n",
    "id(i) , id(j) # problem\n",
    "\n",
    "i = torch.clone(j) # solution\n",
    "id(i) , id(j)\n",
    "\n",
    "i , j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.6352, 1.7477, 2.5755, 2.2724, 2.7095, 2.5869],\n",
       "        [0.4486, 0.8401, 1.0211, 0.7839, 1.1493, 1.0826],\n",
       "        [0.8314, 0.9847, 1.2334, 1.2303, 1.4476, 1.3873],\n",
       "        [1.3702, 1.6120, 1.9183, 1.8423, 2.4025, 2.1910]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor operation using GPU\n",
    "torch.cuda.is_available()\n",
    "\n",
    "device = torch.device(\"cpu\") # for cpu add \"cuda\" instead of \"cpu\"\n",
    "\n",
    "torch.rand(2,3 , dtype= torch.float64 , device= device)\n",
    "\n",
    "a = torch.rand(4,5)\n",
    "b = torch.rand(5,6)\n",
    "\n",
    "a = a.to(device=device)\n",
    "b = b.to(device=device)\n",
    "\n",
    "torch.matmul(a ,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 4, 5])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshaping Tensors\n",
    "\n",
    "a = torch.ones(4,1)\n",
    "a.reshape(2 , 2) # original shape product =  reshaped shape product\n",
    "\n",
    "a.flatten()\n",
    "\n",
    "b = torch.ones(3,4,5)\n",
    "b.permute(1,0 ,2).shape \n",
    "\n",
    "b.unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NUmpy to Torch\n",
    "import numpy as np\n",
    "\n",
    "a = np.array([1,3,4,5])\n",
    "type(a)\n",
    "a = torch.from_numpy(a) # Numpy array to tensor\n",
    "type(a)\n",
    "\n",
    "b = torch.tensor([1,2 , 3,4 ])\n",
    "type(b)\n",
    "b = b.numpy()\n",
    "type(b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
