{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### why : To Create of batches of data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn \n",
    "import torch.optim as opt\n",
    "from sklearn.preprocessing import LabelEncoder , StandardScaler , OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution - just use two loops one for batch and other for epoch\n",
    "# Probelm with this solution - Transformation not possibe, shuffling and sampling not possible , paarllel \n",
    "\n",
    "# DataSet class\n",
    "# __init__ --> from where the data is coming from\n",
    "# __len__ --> give total number of rows\n",
    "# __getitem__ --> return row of given index , also can apply transformation\n",
    "\n",
    "# Data Loader class\n",
    "# shuffle --> make chunks --> pack chunks and make batch --> traning pipeline\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>785</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Ali, Mr. William</td>\n",
       "      <td>male</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/O.Q. 3101312</td>\n",
       "      <td>7.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>325</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sage, Mr. George John Jr</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>69.5500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Olsen, Mr. Karl Siegwart Andreas</td>\n",
       "      <td>male</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4579</td>\n",
       "      <td>8.4042</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>759</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Theobald, Mr. Thomas Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>363294</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>588</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Frolicher-Stehli, Mr. Maxmillian</td>\n",
       "      <td>male</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13567</td>\n",
       "      <td>79.2000</td>\n",
       "      <td>B41</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                              Name   Sex  \\\n",
       "784          785         0       3                  Ali, Mr. William  male   \n",
       "324          325         0       3          Sage, Mr. George John Jr  male   \n",
       "197          198         0       3  Olsen, Mr. Karl Siegwart Andreas  male   \n",
       "758          759         0       3      Theobald, Mr. Thomas Leonard  male   \n",
       "587          588         1       1  Frolicher-Stehli, Mr. Maxmillian  male   \n",
       "\n",
       "      Age  SibSp  Parch              Ticket     Fare Cabin Embarked  \n",
       "784  25.0      0      0  SOTON/O.Q. 3101312   7.0500   NaN        S  \n",
       "324   NaN      8      2            CA. 2343  69.5500   NaN        S  \n",
       "197  42.0      0      1                4579   8.4042   NaN        S  \n",
       "758  34.0      0      0              363294   8.0500   NaN        S  \n",
       "587  60.0      1      1               13567  79.2000   B41        C  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Dataset/Titanic/train.csv\")\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((712, 11), (712,))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocss the datset\n",
    "df = df.drop(columns= ['Name' , 'Cabin' ,\"PassengerId\" , \"Ticket\"])\n",
    "\n",
    "# Split the dataset\n",
    "y = df['Survived']\n",
    "X = df.drop(columns= ['Survived'])\n",
    "X_train , x_test , y_train , y_test = train_test_split(X, y , test_size= 0.2 , random_state= 42)\n",
    "X_train.shape , x_test.shape\n",
    "\n",
    "# impuation for Age\n",
    "Si = SimpleImputer(strategy= \"mean\")\n",
    "X_train['Age'] = Si.fit_transform(X_train[['Age']])\n",
    "x_test['Age'] = Si.transform(x_test[[\"Age\"]])\n",
    "\n",
    "# Impuation for Embarked\n",
    "X_train = X_train.fillna({'Embarked': 'missing'})  # Replace with 'missing' instead of dropping\n",
    "x_test = x_test.fillna({'Embarked': 'missing'})\n",
    "\n",
    "# OHE\n",
    "object_columns = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "ohe = OneHotEncoder(sparse_output= False)\n",
    "\n",
    "X_train_ohe_encoder = ohe.fit_transform(X_train[object_columns])\n",
    "x_test_ohe_encoder = ohe.transform(x_test[object_columns])\n",
    "\n",
    "X_train_ohe_df = pd.DataFrame(X_train_ohe_encoder , columns= ohe.get_feature_names_out(object_columns), index= X_train.index)\n",
    "x_test_ohe_df = pd.DataFrame(x_test_ohe_encoder , columns= ohe.get_feature_names_out(object_columns) , index= x_test.index)\n",
    "\n",
    "X_train = pd.concat([X_train , X_train_ohe_df] , axis= 1)\n",
    "x_test = pd.concat([x_test , x_test_ohe_df] , axis= 1)\n",
    "\n",
    "X_train = X_train.drop(object_columns , axis= 1)\n",
    "x_test = x_test.drop(object_columns , axis= 1)\n",
    "\n",
    "# Scale Values\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "# Label Encoder\n",
    "LE = LabelEncoder()\n",
    "y_train = LE.fit_transform(y_train)\n",
    "y_test = LE.transform(y_test)\n",
    "X_train.shape , y_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting into tensor\n",
    "import numpy as np \n",
    "\n",
    "X_train = np.array(X_train)\n",
    "x_test = np.array(x_test)\n",
    "X_train = torch.from_numpy(X_train)\n",
    "x_test = torch.from_numpy(x_test)\n",
    "y_test = torch.from_numpy(y_test)\n",
    "y_train = torch.from_numpy(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader , Dataset\n",
    "\n",
    "class CustomDataSet(Dataset):\n",
    "    def __init__(self, features , labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.features.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.features[index] , self.labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset =CustomDataSet(X_train , y_train)\n",
    "dataloader_train = DataLoader(dataset , batch_size= 16 , shuffle= True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 11])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 11])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 11])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 11])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 11])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 11])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 11])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 11])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 11])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 11])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 11])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 11])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 11])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 11])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 11])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 11])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 11])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 11])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 11])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 11])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 11])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 11])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 11])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 11])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 11])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 11])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 11])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 11])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 11])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 11])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 11])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 11])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 11])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 11])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 11])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 11])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 11])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 11])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 11])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 11])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 11])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 11])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 11])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 11])\n",
      "torch.Size([16])\n",
      "torch.Size([8, 11])\n",
      "torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "for batch_feartures , batch_lables in dataloader_train: # Create batches od data\n",
    "    print(batch_feartures.shape)\n",
    "    print(batch_lables.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callate_fn --> in dataloder class , merge data to combine data tensor to create batches\n",
    "# num_worker --> to run parllel \n",
    "# sampler --> how to sample from the data using dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Sequentailly container \n",
    "# Model Creation\n",
    "class NeuralNetworkFinal(nn.Module):\n",
    "    def __init__(self , Feature_count):\n",
    "        super().__init__() \n",
    "        self.network = nn.Sequential(       \n",
    "        nn.Linear(Feature_count , 5),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear( 5 ,3 ),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(3 ,1),\n",
    "        nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        \n",
    "    def forward(self , features):\n",
    "        out = self.network(features)   \n",
    "        return out\n",
    "\n",
    "loss_funtion = nn.BCELoss()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "NeuralNetworkFinal                       [712, 1]                  --\n",
       "├─Sequential: 1-1                        [712, 1]                  --\n",
       "│    └─Linear: 2-1                       [712, 5]                  60\n",
       "│    └─ReLU: 2-2                         [712, 5]                  --\n",
       "│    └─Linear: 2-3                       [712, 3]                  18\n",
       "│    └─ReLU: 2-4                         [712, 3]                  --\n",
       "│    └─Linear: 2-5                       [712, 1]                  4\n",
       "│    └─Sigmoid: 2-6                      [712, 1]                  --\n",
       "==========================================================================================\n",
       "Total params: 82\n",
       "Trainable params: 82\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.06\n",
       "==========================================================================================\n",
       "Input size (MB): 0.03\n",
       "Forward/backward pass size (MB): 0.05\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.08\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "lr = 0.1\n",
    "epoch = 20\n",
    "X_train = X_train.to(dtype= torch.float32)\n",
    "x_test = x_test.to(dtype= torch.float32)\n",
    "y_test = y_test.to(dtype= torch.float32)\n",
    "y_train = y_train.to(dtype= torch.float32)\n",
    "\n",
    "# Creating model instance\n",
    "model = NeuralNetworkFinal(X_train.shape[1])\n",
    "optimiser = opt.Adam(model.parameters() , lr)\n",
    " \n",
    "\n",
    "summary(model , (712, 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 , loss : 0.5319356918334961\n",
      "Epoch : 2 , loss : 0.7131079435348511\n",
      "Epoch : 3 , loss : 0.6126660108566284\n",
      "Epoch : 4 , loss : 0.7104718089103699\n",
      "Epoch : 5 , loss : 0.6636423468589783\n",
      "Epoch : 6 , loss : 0.6813210844993591\n",
      "Epoch : 7 , loss : 0.6615707278251648\n",
      "Epoch : 8 , loss : 0.5943147540092468\n",
      "Epoch : 9 , loss : 0.5768144130706787\n",
      "Epoch : 10 , loss : 0.8149781227111816\n",
      "Epoch : 11 , loss : 0.7521846294403076\n",
      "Epoch : 12 , loss : 0.5862138271331787\n",
      "Epoch : 13 , loss : 0.5740678310394287\n",
      "Epoch : 14 , loss : 0.6615975499153137\n",
      "Epoch : 15 , loss : 0.5695509314537048\n",
      "Epoch : 16 , loss : 0.6620679497718811\n",
      "Epoch : 17 , loss : 0.8652433156967163\n",
      "Epoch : 18 , loss : 0.6619473099708557\n",
      "Epoch : 19 , loss : 0.6652827262878418\n",
      "Epoch : 20 , loss : 0.602824866771698\n"
     ]
    }
   ],
   "source": [
    "# Training pipe line --> here we wil be integrate dataloder class\n",
    "\n",
    "for ep in range(epoch):\n",
    "    for batch_feartures , batch_lables in dataloader_train:\n",
    "        \n",
    "        batch_feartures = batch_feartures.to(dtype = torch.float32)\n",
    "        batch_lables =  batch_lables.to(dtype = torch.float32)\n",
    "        # Forward pass\n",
    "        y_pred = model(batch_feartures)\n",
    "        \n",
    "        # Loss calculation\n",
    "        loss = loss_funtion(y_pred , batch_lables.view(-1 ,1 ))\n",
    "        \n",
    "        # clear gradient \n",
    "        optimiser.zero_grad()\n",
    "        \n",
    "        # Backprog loss\n",
    "        loss.backward()\n",
    "        \n",
    "        # paramter upadates\n",
    "        optimiser.step()\n",
    "        \n",
    "    print(f\"Epoch : {ep+1} , loss : {loss}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomDataSet(x_test , y_test)\n",
    "dataloader_test = DataLoader(test_dataset , batch_size= 16 , shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.569444477558136\n"
     ]
    }
   ],
   "source": [
    "# model Evalution\n",
    "# Evaluate the model\n",
    "\n",
    "model.eval()\n",
    "acc_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_feartures , batch_lables in dataloader_test:\n",
    "        \n",
    "        batch_feartures = batch_feartures.to(dtype = torch.float32)\n",
    "        batch_lables =  batch_lables.to(dtype = torch.float32)\n",
    "    \n",
    "        y_pred = model.forward(batch_feartures)\n",
    "        y_pred = (y_pred > 0.6).float()  # threshold = 0.6\n",
    "        \n",
    "        acc = (y_pred == batch_lables).float().mean() # to calculate accuracy\n",
    "        acc_list.append(acc)\n",
    "       \n",
    "overall_acc = sum(acc_list) / len(acc_list)\n",
    "print(f\"Accuracy: {overall_acc}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
