{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the liberaries \n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader , Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6062</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18899</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16762</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3029</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11446</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "6062       1       0       0       0       0       0       0       0       0   \n",
       "18899      9       0       0       0       0       0       0       0       0   \n",
       "16762      9       0       0       0       0       0       0       0       0   \n",
       "3029       1       0       0       0       0       0       0       0       0   \n",
       "11446      6       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "6062        0  ...         0         0         0         0         0   \n",
       "18899       0  ...         0         0         0         0         0   \n",
       "16762       0  ...         0         0         0         0         0   \n",
       "3029        0  ...         0         0         0         0         0   \n",
       "11446       0  ...         0         0         0         0         0   \n",
       "\n",
       "       pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "6062          0         0         0         0         0  \n",
       "18899         0         0         0         0         0  \n",
       "16762         0         0         0         0         0  \n",
       "3029          0         0         0         0         0  \n",
       "11446         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import minist dataset\n",
    "df = pd.read_csv(\"Dataset/Mnist/train.csv\")\n",
    "df = df.iloc[:100000]\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set split\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df[\"label\"]\n",
    "x = df.drop(columns= [\"label\"])\n",
    "x_train , x_test , y_train , y_test  = train_test_split(x , y , test_size= 0.2 , random_state= 42)\n",
    "x_train.shape , y_train.shape\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "x_train = torch.from_numpy(x_train)\n",
    "x_test = torch.from_numpy(x_test)\n",
    "y_train = torch.from_numpy(y_train)\n",
    "y_test = torch.from_numpy(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model class\n",
    "import torch.optim as opt\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self , feature_count):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(feature_count , 256 , bias= True),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p= 0.4),\n",
    "            nn.Linear(256 , 128 , bias= True),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p = 0.4),\n",
    "            nn.Linear(128 , 64 ),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p = 0.4),\n",
    "            nn.Linear(64 , 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self , features):\n",
    "        out = self.network(features)\n",
    "        return out\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset class\n",
    "class CustomeDataset(Dataset):\n",
    "    def __init__(self, featues , lables):\n",
    "        \n",
    "        self.features = featues.to(dtype = torch.float32)\n",
    "        self.features = self.features/255\n",
    "        self.labels = lables.to(dtype = torch.long)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.features.shape[0]\n",
    "    \n",
    "    def __getitem__(self , index):\n",
    "        return self.features[index] , self.labels[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare hyperparamater \n",
    "batch_size = 16\n",
    "lr = 0.01\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init model and Dataloder \n",
    "dataset_train = CustomeDataset(x_train , y_train)\n",
    "dataloder_train = DataLoader(dataset_train , shuffle= True , batch_size= batch_size)\n",
    "\n",
    "# Model\n",
    "model = NeuralNetwork(x_train.shape[1])\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "opti = opt.Adam(model.parameters() , lr = lr, weight_decay= 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "NeuralNetwork                            [33600, 10]               --\n",
       "├─Sequential: 1-1                        [33600, 10]               --\n",
       "│    └─Linear: 2-1                       [33600, 256]              200,960\n",
       "│    └─BatchNorm1d: 2-2                  [33600, 256]              512\n",
       "│    └─ReLU: 2-3                         [33600, 256]              --\n",
       "│    └─Dropout: 2-4                      [33600, 256]              --\n",
       "│    └─Linear: 2-5                       [33600, 128]              32,896\n",
       "│    └─BatchNorm1d: 2-6                  [33600, 128]              256\n",
       "│    └─ReLU: 2-7                         [33600, 128]              --\n",
       "│    └─Dropout: 2-8                      [33600, 128]              --\n",
       "│    └─Linear: 2-9                       [33600, 64]               8,256\n",
       "│    └─BatchNorm1d: 2-10                 [33600, 64]               128\n",
       "│    └─ReLU: 2-11                        [33600, 64]               --\n",
       "│    └─Dropout: 2-12                     [33600, 64]               --\n",
       "│    └─Linear: 2-13                      [33600, 10]               650\n",
       "==========================================================================================\n",
       "Total params: 243,658\n",
       "Trainable params: 243,658\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 8.19\n",
       "==========================================================================================\n",
       "Input size (MB): 105.37\n",
       "Forward/backward pass size (MB): 243.53\n",
       "Params size (MB): 0.97\n",
       "Estimated Total Size (MB): 349.88\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(model , input_size=(33600, 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 , Loss : 0.6840712177913104\n",
      "Epoch : 2 , Loss : 0.5600343158025117\n",
      "Epoch : 3 , Loss : 0.5567376774088257\n",
      "Epoch : 4 , Loss : 0.5502525425968425\n",
      "Epoch : 5 , Loss : 0.5476103959693795\n",
      "Epoch : 6 , Loss : 0.541609094307891\n",
      "Epoch : 7 , Loss : 0.5524053821003153\n",
      "Epoch : 8 , Loss : 0.5466694559689079\n",
      "Epoch : 9 , Loss : 0.5408433848477545\n",
      "Epoch : 10 , Loss : 0.5430879700982145\n",
      "Epoch : 11 , Loss : 0.5457507459216174\n",
      "Epoch : 12 , Loss : 0.5516801993300517\n",
      "Epoch : 13 , Loss : 0.5440792318947968\n",
      "Epoch : 14 , Loss : 0.5433670913445807\n",
      "Epoch : 15 , Loss : 0.5514682091382288\n",
      "Epoch : 16 , Loss : 0.5496487689905223\n",
      "Epoch : 17 , Loss : 0.5440142103976437\n",
      "Epoch : 18 , Loss : 0.5376077573409392\n",
      "Epoch : 19 , Loss : 0.5524326012212606\n",
      "Epoch : 20 , Loss : 0.5451419158634685\n"
     ]
    }
   ],
   "source": [
    "# traing Loop\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_epoch_loss = 0\n",
    "    \n",
    "    for train_features , train_lables in dataloder_train:\n",
    "        \n",
    "        # forward pass\n",
    "        y_pred = model(train_features)\n",
    "        \n",
    "        # Loss calculation\n",
    "        loss = loss_function(y_pred , train_lables)\n",
    "        \n",
    "        # clear gradient \n",
    "        opti.zero_grad()\n",
    "         \n",
    "        # backpropgation\n",
    "        loss.backward()\n",
    "        \n",
    "        # paramter updates\n",
    "        opti.step()\n",
    "        \n",
    "        total_epoch_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch : {epoch+1} , Loss : {total_epoch_loss/len(dataloder_train)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (network): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.4, inplace=False)\n",
       "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): Dropout(p=0.4, inplace=False)\n",
       "    (8): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (9): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU()\n",
       "    (11): Dropout(p=0.4, inplace=False)\n",
       "    (12): Linear(in_features=64, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval() # for diff behavior in train and eval, like drop out or batchnor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9308333333333333\n"
     ]
    }
   ],
   "source": [
    "# Evalution forTestingData\n",
    "test_dataset = CustomeDataset(x_test , y_test)\n",
    "test_dataloder = DataLoader(test_dataset , batch_size= 16 , shuffle= False)\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for test_feat , test_label in test_dataloder:\n",
    "        \n",
    "        output = model(test_feat)\n",
    "        \n",
    "        _ , pos = torch.max(output , dim= 1)\n",
    "        \n",
    "        total += test_label.shape[0]\n",
    "        \n",
    "        correct += (pos == test_label).sum().item()\n",
    "    \n",
    "    print(f\"TestingAccuracy : {correct/total}\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingAccuracy : 0.9352976190476191\n"
     ]
    }
   ],
   "source": [
    "# Evalution forTrainingData\n",
    "test_dataset = CustomeDataset(x_test , y_test)\n",
    "test_dataloder = DataLoader(test_dataset , batch_size= 16 , shuffle= False)\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for test_feat , test_label in dataloder_train:\n",
    "        \n",
    "        output = model(test_feat)\n",
    "        \n",
    "        _ , pos = torch.max(output , dim= 1)\n",
    "        \n",
    "        total += test_label.shape[0]\n",
    "        \n",
    "        correct += (pos == test_label).sum().item()\n",
    "    \n",
    "    print(f\"TrainingAccuracy : {correct/total}\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
